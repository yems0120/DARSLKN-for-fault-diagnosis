{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import trange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# K折交叉验证\n",
    "def k_fold(data_X, data_y, name, device='cpu',\n",
    "           k=5, num_epochs=50, learning_rate=1e-3, weight_decay=0.0, batch_size=128):\n",
    "    train_l_sum, valid_l_sum = [], []\n",
    "    train_total_time = 0.0\n",
    "    for i in range(k):\n",
    "        data = get_k_fold_data(k, i, data_X, data_y) # X_train, y_train, X_valid, y_valid\n",
    "        net = get_net(device)\n",
    "        train_ls, valid_ls, train_time = train(name, i, net, *data, num_epochs, learning_rate, weight_decay, batch_size, device)\n",
    "        index = valid_ls.index(max(valid_ls)) # 返回列表最大值的索引\n",
    "        # train_l_sum += train_ls[index]\n",
    "        # valid_l_sum += valid_ls[index]\n",
    "        train_l_sum.append(train_ls[index])\n",
    "        valid_l_sum.append(valid_ls[index])\n",
    "        train_total_time += train_time\n",
    "        print(f'折{i + 1}, train_time(second): {train_time}' )\n",
    "        print(f'折{i + 1}, 训练log accuracy{float(train_ls[index]):f}, '\n",
    "              f'验证log accuracy{float(valid_ls[index]):f}')\n",
    "\n",
    "    return np.mean(train_l_sum), np.mean(valid_l_sum), np.std(valid_l_sum), train_total_time / k\n",
    "\n",
    "def get_k_fold_data(k, i, X, y):\n",
    "    assert k > 1\n",
    "    fold_size = X.shape[0] // k\n",
    "    X_train, y_train = None, None\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size)\n",
    "        X_part, y_part = X[idx, :], y[idx]\n",
    "        if j == i:\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None:\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else:\n",
    "            X_train = torch.cat([X_train, X_part], 0)\n",
    "            y_train = torch.cat([y_train, y_part], 0)\n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "\n",
    "def build_dataloader(data_x, data_y, BATCH_SIZE=128, is_train=True):\n",
    "    # 构造一个Pytorch数据迭代器\n",
    "    data_tensor = TensorDataset(data_x, data_y)                    \n",
    "    data_loader = DataLoader(dataset=data_tensor, batch_size=BATCH_SIZE, shuffle=is_train)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练+验证\n",
    "def train(name, i, net, train_features, train_labels, test_features, test_labels,\n",
    "          num_epochs, learning_rate, weight_decay, batch_size, device):\n",
    "    # writer = SummaryWriter(log_dir=f'logs/{name}/折{i+1}')\n",
    "    # writer = {'train_loss': SummaryWriter(log_dir=f'logs/{name}/折{i+1}/train'),\n",
    "    #           'test_loss': SummaryWriter(log_dir=f'logs/{name}/折{i+1}/test')}\n",
    "    train_ls, test_ls = [], []\n",
    "    train_iter = build_dataloader(train_features, train_labels, batch_size) # train_loader\n",
    "    test_iter = build_dataloader(test_features, test_labels, batch_size) # test_loader\n",
    "    # Adam优化算法\n",
    "    optimizer = torch.optim.Adam(net.parameters(),\n",
    "                                 lr = learning_rate,\n",
    "                                 weight_decay = weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    total_time = 0.0\n",
    "    # max_correct = 0.0\n",
    "    BEST_LOSS = np.inf # 学习率衰减\n",
    "    patience_counter = 0    \n",
    "    for epoch in trange(1, num_epochs+1):\n",
    "        net.train()\n",
    "        start = time.time()\n",
    "        total_loss = 0.0\n",
    "        for ii, batch in enumerate(train_iter):\n",
    "            X, y = batch\n",
    "            X, y = X.unsqueeze(1).to(device=device), y.to(device=device)\n",
    "            pre = net(X)\n",
    "            loss = criterion(pre, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss +=loss.item()\n",
    "        \n",
    "        end = time.time()\n",
    "        time_elapsed = end - start\n",
    "        # writer.add_scalar(\"Time/train\", time_elapsed, epoch)\n",
    "        total_time += time_elapsed\n",
    "\n",
    "        net.eval()\n",
    "        for NAME, loader in [(\"train\", train_iter), (\"test\", test_iter)]:\n",
    "            loss_sum = 0.0\n",
    "            correct = 0.0\n",
    "            total = 0.0\n",
    "            for x_input, y_label in loader:\n",
    "                x_input, y_label = x_input.unsqueeze(1).to(device=device), y_label.to(device=device)\n",
    "                y_pred = net(x_input)\n",
    "                LOSS = criterion(y_pred, y_label)\n",
    "                loss_sum += LOSS.item()\n",
    "                _, predicted = torch.max(y_pred, dim=1)\n",
    "\n",
    "                total += y_label.shape[0]\n",
    "                correct += int((predicted == y_label).sum())\n",
    "                \n",
    "            if NAME == 'train':\n",
    "                train_ls.append(correct/total)\n",
    "                # writer['train_loss'].add_scalar(\"Loss\", loss_sum/len(loader), epoch)\n",
    "                \n",
    "            else:\n",
    "                # 保存权重\n",
    "                # if correct > max_correct:\n",
    "                #     max_correct = correct\n",
    "                #     torch.save(net, f'{name}.pth')\n",
    "                    \n",
    "                test_ls.append(correct/total)\n",
    "                # writer['test_loss'].add_scalar(\"Loss\", loss_sum/len(loader), epoch)\n",
    "                \n",
    "                # 学习率衰减\n",
    "                if loss_sum < BEST_LOSS:\n",
    "                    BEST_LOSS = loss_sum\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    if patience_counter >= 5 :\n",
    "                        learning_rate = 0.2*learning_rate \n",
    "                        # print(learning_rate)\n",
    "                        optimizer = torch.optim.Adam(net.parameters(),\n",
    "                                                    lr = learning_rate,\n",
    "                                                    weight_decay = weight_decay)\n",
    "                        patience_counter = 0 \n",
    "            # writer.add_scalar(name, correct/total, epoch)\n",
    "            \n",
    "    # writer['train_loss'].close()\n",
    "    # writer['test_loss'].close()   \n",
    "    return train_ls, test_ls, total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda.\n"
     ]
    }
   ],
   "source": [
    "from modules.data_processing import *\n",
    "# from modules.setup_seed import *\n",
    "# from modules.cross_validation import k_fold\n",
    "\n",
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "            else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")\n",
    "\n",
    "data_x = np.load('./data/Bearing_Zhaomh/SNR-N5/data_x.npy')\n",
    "data_y = np.load('./data/Bearing_Zhaomh/SNR-N5/data_y.npy')\n",
    "data_x, data_y = data_processing(data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# __all__ = ('CBAM', 'SENet', 'autopad', 'Conv', 'Bottleneck, 'C2f', 'ARNet')\n",
    "\n",
    "# CBAM 注意力\n",
    "class ChannelAttention(nn.Module):\n",
    "    \"\"\"Channel-attention module https://github.com/open-mmlab/mmdetection/tree/v3.0.0rc1/configs/rtmdet.\"\"\"\n",
    "    def __init__(self, channels: int) -> None:\n",
    "        super().__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Conv1d(channels, channels, 1, 1, 0, bias=True)\n",
    "        self.act = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x * self.act(self.fc(self.pool(x)))\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    \"\"\"Spatial-attention module.\"\"\"\n",
    "    def __init__(self, kernel_size=7):\n",
    "        \"\"\"Initialize Spatial-attention module with kernel size argument.\"\"\"\n",
    "        super().__init__()\n",
    "        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n",
    "        padding = 3 if kernel_size == 7 else 1\n",
    "        self.cv1 = nn.Conv1d(2, 1, kernel_size, padding=padding, bias=False)\n",
    "        self.act = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Apply channel and spatial attention on input for feature recalibration.\"\"\"\n",
    "        return x * self.act(self.cv1(torch.cat([torch.mean(x, 1, keepdim=True), torch.max(x, 1, keepdim=True)[0]], 1))) \n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    \"\"\"Convolutional Block Attention Module.\"\"\"\n",
    "    def __init__(self, c1, kernel_size=7):  # ch_in, kernels\n",
    "        super().__init__()\n",
    "        self.channel_attention = ChannelAttention(c1)\n",
    "        self.spatial_attention = SpatialAttention(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Applies the forward pass through C1 module.\"\"\"\n",
    "        return self.spatial_attention(self.channel_attention(x))\n",
    "# CBAM 注意力\n",
    "\n",
    "\n",
    "# SE 注意力\n",
    "class SENet(nn.Module):\n",
    "    def __init__(self, channels, ratio=16):\n",
    "        super(SENet, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, channels//ratio, False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(channels//ratio, channels, False),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, c, L = x.size()\n",
    "        avg = self.avg_pool(x).view([N, c])\n",
    "        fc = self.fc(avg).view([N, c, 1])\n",
    "\n",
    "        return x*fc\n",
    "# SE 注意力\n",
    "\n",
    "# ECA 注意力\n",
    "class EfficientChannelAttention(nn.Module):\n",
    "    def __init__(self, c, b=1, gamma=2):\n",
    "        super(EfficientChannelAttention, self).__init__()\n",
    "        t = int(abs((math.log(c, 2) + b) / gamma))\n",
    "        k = t if t % 2 else t + 1\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.conv1 = nn.Conv1d(1, 1, kernel_size=k, padding=int(k/2), bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg = self.avg_pool(x) # B*C*1\n",
    "        fc = self.conv1(avg.transpose(-1, -2)).transpose(-1, -2)\n",
    "        fc = self.sigmoid(fc)\n",
    "        return x*fc\n",
    "# ECA 注意力\n",
    "\n",
    "def autopad(k, p=None, d=1):  # kernel, padding, dilation\n",
    "    \"\"\"Pad to 'same' shape outputs.\"\"\"\n",
    "    if d > 1:\n",
    "        k = d * (k - 1) + 1 if isinstance(k, int) else [d * (x - 1) + 1 for x in k]  # actual kernel-size\n",
    "    if p is None:\n",
    "        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]  # auto-pad\n",
    "    return p\n",
    "\n",
    "\n",
    "class Conv(nn.Module):\n",
    "    \"\"\"Standard convolution with args(ch_in, ch_out, kernel, stride, padding, groups, dilation, activation).\"\"\"\n",
    "    default_act = nn.SiLU() # default activation\n",
    "\n",
    "    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, d=1, act=True):\n",
    "        \"\"\"Initialize Conv layer with given arguments including activation.\"\"\"\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(c1, c2, k, s, autopad(k, p, d), groups=g, dilation=d, bias=False)\n",
    "        self.bn = nn.BatchNorm1d(c2)\n",
    "        self.act = self.default_act if act is True else act if isinstance(act, nn.Module) else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Apply convolution, batch normalization and activation to input tensor.\"\"\"\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "    \n",
    "    \n",
    "class Bottleneck(nn.Module):  \n",
    "    \"\"\"DarknetBottleneck\"\"\"\n",
    "    def __init__(self, c1, c2, shortcut=True, e=0.5,\n",
    "                 k1=19, d1=2, k2=17, d2=4):\n",
    "        super().__init__()\n",
    "        c_ = int(c2 * e)  # hidden channels\n",
    "        self.cv1 = Conv(c1, c_, k=k1, p=autopad(k=k1, d=d1), d=d1)\n",
    "        self.cv2 = Conv(c_, c2, k=k2, p=autopad(k=k2, d=d2), d=d2)\n",
    "        self.add = shortcut and c1 == c2\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))\n",
    "    \n",
    "\n",
    "class C2f(nn.Module):  # CSPLayer_2Conv\n",
    "    \"\"\"Faster Implementation of CSP Bottleneck with 2 convolutions.\"\"\"\n",
    "    def __init__(self, c1, c2, n=1, shortcut=True, e=0.5,\n",
    "                 k1=19, d1=2, k2=17, d2=4):\n",
    "        super().__init__()\n",
    "        self.c = int(c2 * e)  # hidden channels\n",
    "        self.cv1 = Conv(c1, 2 * self.c, 1, 1)\n",
    "        self.cv2 = Conv((2 + n) * self.c, c2, 1)\n",
    "        self.m = nn.ModuleList(Bottleneck(self.c, self.c, shortcut, 1, k1, d1, k2, d2) for _ in range(n))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through C2f layer.\"\"\"\n",
    "        y = list(self.cv1(x).chunk(2, 1))   \n",
    "        y.extend(m(y[-1]) for m in self.m)  \n",
    "        return self.cv2(torch.cat(y, 1))  # Concat -> ConvModule\n",
    "    \n",
    "class ARNet(nn.Module): # Adaptive_Rank\n",
    "    def __init__(self, channels, ratio=1):\n",
    "        super(ARNet, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, channels//ratio, False),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(channels//ratio, channels, False),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, L = x.size()\n",
    "        avg = self.avg_pool(x).view([B, C])\n",
    "        fc = self.fc(avg).view([B, C, 1])\n",
    "        x = x*fc\n",
    "        indices = torch.argsort(fc, dim=1, descending=False).expand(B, C, L)\n",
    "        x = torch.gather(x, dim=1, index=indices)\n",
    "        return x\n",
    "\n",
    "# class ARNet(nn.Module):\n",
    "#     def __init__(self, channels, b=1, gamma=2):\n",
    "#         super(ARNet, self).__init__()\n",
    "#         t = int(abs((math.log(channels, 2) + b) / gamma))\n",
    "#         k = t if t % 2 else t + 1\n",
    "#         self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "#         self.conv1 = nn.Conv1d(1, 1, kernel_size=k, padding=int(k/2), bias=False)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         B, C, L = x.size()\n",
    "#         avg = self.avg_pool(x) # B*C*1\n",
    "#         fc = self.conv1(avg.transpose(-1, -2)).transpose(-1, -2)\n",
    "#         fc = self.sigmoid(fc)\n",
    "#         x = x*fc\n",
    "#         indices = torch.argsort(fc, dim=1, descending=False).expand(B, C, L)\n",
    "#         x = torch.gather(x, dim=1, index=indices)\n",
    "#         return x\n",
    "   \n",
    "   \n",
    "class dilated_c2f1(nn.Module):\n",
    "    def __init__(self, c1, c2, n=1, shortcut=True, e=1,\n",
    "                 k1=19, d1=2, k2=17, d2=4):\n",
    "        super().__init__()\n",
    "        self.c = c1//2\n",
    "        self.ar = ARNet(channels=c1)        \n",
    "        self.cv = Conv((2 + n) * self.c, c2, 1)\n",
    "        self.m = nn.ModuleList(Bottleneck(self.c, self.c, shortcut, e, k1, d1, k2, d2) for _ in range(n))\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = list(self.ar(x).chunk(2, 1))\n",
    "        y.extend(m(y[-1]) for m in self.m)  \n",
    "        return self.cv(torch.cat(y, 1))\n",
    "    \n",
    "    \n",
    "class dilated_c2f2(nn.Module):\n",
    "    def __init__(self, c1, c2, n=1, shortcut=True, e=1,\n",
    "                 k1=19, d1=2, k2=17, d2=4):\n",
    "        super().__init__()\n",
    "        self.c = c1//3\n",
    "        self.ar1 = ARNet(channels=c1)\n",
    "        self.ar2 = ARNet(channels=(c1-self.c))         \n",
    "        self.cv = Conv((5 + n) * self.c, c2, 1)\n",
    "        self.m1 = nn.ModuleList(Bottleneck(2*self.c, 2*self.c, shortcut, e, k1, d1, k2, d2) for _ in range(1))\n",
    "        self.m2 = nn.ModuleList(Bottleneck(self.c, self.c, shortcut, e, k1, d1, k2, d2) for _ in range(n))\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = list(torch.tensor_split(self.ar1(x), (self.c,), dim=1))\n",
    "        y.extend(m1(y[-1]) for m1 in self.m1)\n",
    "        x = self.ar2(y[-1])\n",
    "        y.pop()\n",
    "        y.extend(x.chunk(2, 1))\n",
    "        y.extend(m2(y[-1]) for m2 in self.m2)\n",
    "        return self.cv(torch.cat(y, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    c = 48\n",
    "    self.conv0 = Conv(1, c, k=1, s=1)\n",
    "\n",
    "    self.conv1 = Conv(c, 2*c, k=3, s=2, p=1)\n",
    "    self.c2f1 = Bottleneck(2*c, 2*c, shortcut=True, e=0.5,\n",
    "                           k1=3, d1=1, k2=3, d2=1)\n",
    "    \n",
    "    self.conv2 = Conv(2*c, 3*c, k=3, s=2, p=1)\n",
    "    self.c2f2 = nn.Sequential(\n",
    "        Bottleneck(3*c, 3*c, shortcut=True, e=0.333,\n",
    "                           k1=3, d1=1, k2=3, d2=1),\n",
    "        Bottleneck(3*c, 3*c, shortcut=True, e=0.333,\n",
    "                           k1=3, d1=1, k2=3, d2=1)\n",
    "    )\n",
    "    \n",
    "    self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "    self.drop = nn.Dropout(p=0.)\n",
    "    self.fc = nn.Linear(3*c, 5)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    # x.shape: (batch, 1024, 1)\n",
    "    x = self.conv0(x)\n",
    "\n",
    "    x = self.conv1(x)\n",
    "    x = self.c2f1(x)\n",
    "    \n",
    "    x = self.conv2(x)\n",
    "    x = self.c2f2(x)\n",
    "    \n",
    "    x = self.pool(x).flatten(1)\n",
    "    x = self.drop(x)\n",
    "    x = self.fc(x) \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C2fNet(torch.nn.Module):  # You Only Read Once\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    c = 48\n",
    "    self.conv0 = Conv(1, c, k=1, s=1)\n",
    "\n",
    "    self.conv1 = Conv(c, 2*c, k=3, s=2, p=1)\n",
    "    self.c2f1 = C2f(2*c, 2*c, n=1, shortcut=True, e=0.5,\n",
    "                    k1=3, d1=1, k2=3, d2=1)\n",
    "\n",
    "    self.conv2 = Conv(2*c, 3*c, k=3, s=2, p=1)\n",
    "    self.c2f2 = C2f(3*c, 3*c, n=2, shortcut=True, e=0.5,\n",
    "                    k1=3, d1=1, k2=3, d2=1)    \n",
    "\n",
    "    self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "    self.drop = nn.Dropout(p=0.)\n",
    "    self.fc = nn.Linear(3*c, 5)\n",
    "\n",
    "  def forward(self, x):\n",
    "    # x.shape: (batch, 1024, 1)\n",
    "    x = self.conv0(x)\n",
    "\n",
    "    x = self.conv1(x)\n",
    "    x = self.c2f1(x)\n",
    "\n",
    "    x = self.conv2(x)\n",
    "    x = self.c2f2(x)\n",
    "\n",
    "    x = self.pool(x).flatten(1)\n",
    "    x = self.drop(x)\n",
    "    x = self.fc(x) \n",
    "    return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSPNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    c = 48\n",
    "    self.conv0 = Conv(1, c, k=1, s=1)\n",
    "\n",
    "    self.conv1 = Conv(c, 2*c, k=3, s=2, p=1)\n",
    "    self.c2f1 = dilated_c2f1(2*c, 2*c, n=1, shortcut=True, e=1,\n",
    "                             k1=3, d1=1, k2=3, d2=1)\n",
    "    \n",
    "    self.conv2 = Conv(2*c, 3*c, k=3, s=2, p=1)\n",
    "    self.c2f2 = dilated_c2f2(3*c, 3*c, n=1, shortcut=True, e=1,\n",
    "                             k1=3, d1=1, k2=3, d2=1)\n",
    "    \n",
    "    self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "    self.drop = nn.Dropout(p=0.)\n",
    "    self.fc = nn.Linear(3*c, 5)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    # x.shape: (batch, 1024, 1)\n",
    "    x = self.conv0(x)\n",
    "\n",
    "    x = self.conv1(x)\n",
    "    x = self.c2f1(x)\n",
    "    \n",
    "    x = self.conv2(x)\n",
    "    x = self.c2f2(x)\n",
    "    \n",
    "    x = self.pool(x).flatten(1)\n",
    "    x = self.drop(x)\n",
    "    x = self.fc(x) \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入尺寸为:torch.Size([5, 1, 1024])\n",
      "输出尺寸为:torch.Size([5, 5])\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv: 1-1                              [-1, 48, 1024]            --\n",
      "|    └─Conv1d: 2-1                       [-1, 48, 1024]            48\n",
      "|    └─BatchNorm1d: 2-2                  [-1, 48, 1024]            96\n",
      "|    └─SiLU: 2-3                         [-1, 48, 1024]            --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-4                         [-1, 48, 1024]            --\n",
      "├─Bottleneck: 1                          []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-1                    [-1, 48, 1024]            --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-2                    [-1, 48, 1024]            --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-5                         [-1, 48, 1024]            --\n",
      "├─Conv: 1-2                              [-1, 96, 512]             --\n",
      "|    └─Conv1d: 2-6                       [-1, 96, 512]             13,824\n",
      "|    └─BatchNorm1d: 2-7                  [-1, 96, 512]             192\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-8                         [-1, 96, 512]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-9                         [-1, 96, 512]             --\n",
      "├─Bottleneck: 1                          []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-3                    [-1, 96, 512]             --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-4                    [-1, 96, 512]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-10                        [-1, 96, 512]             --\n",
      "├─Bottleneck: 1-3                        [-1, 96, 512]             --\n",
      "|    └─Conv: 2-11                        [-1, 48, 512]             --\n",
      "|    |    └─Conv1d: 3-5                  [-1, 48, 512]             179,712\n",
      "|    |    └─BatchNorm1d: 3-6             [-1, 48, 512]             96\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-12                        [-1, 48, 512]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-13                        [-1, 48, 512]             --\n",
      "├─Bottleneck: 1                          []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-7                    [-1, 48, 512]             --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-8                    [-1, 48, 512]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-14                        [-1, 48, 512]             --\n",
      "├─Bottleneck: 1                          []                        --\n",
      "|    └─Conv: 2-15                        [-1, 96, 512]             --\n",
      "|    |    └─Conv1d: 3-9                  [-1, 96, 512]             161,280\n",
      "|    |    └─BatchNorm1d: 3-10            [-1, 96, 512]             192\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-16                        [-1, 96, 512]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-17                        [-1, 96, 512]             --\n",
      "├─Bottleneck: 1                          []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-11                   [-1, 96, 512]             --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-12                   [-1, 96, 512]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-18                        [-1, 96, 512]             --\n",
      "├─Conv: 1-4                              [-1, 144, 256]            --\n",
      "|    └─Conv1d: 2-19                      [-1, 144, 256]            41,472\n",
      "|    └─BatchNorm1d: 2-20                 [-1, 144, 256]            288\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-21                        [-1, 144, 256]            --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-22                        [-1, 144, 256]            --\n",
      "├─Bottleneck: 1                          []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-13                   [-1, 144, 256]            --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-14                   [-1, 144, 256]            --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-23                        [-1, 144, 256]            --\n",
      "├─Sequential: 1-5                        [-1, 144, 256]            --\n",
      "|    └─Bottleneck: 2-24                  [-1, 144, 256]            --\n",
      "|    |    └─Conv: 3-15                   [-1, 47, 256]             196,366\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-25                        [-1, 47, 256]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-26                        [-1, 47, 256]             --\n",
      "├─Bottleneck: 1                          []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-16                   [-1, 47, 256]             --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-17                   [-1, 47, 256]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-27                        [-1, 47, 256]             --\n",
      "├─Sequential: 1                          []                        --\n",
      "|    └─Bottleneck: 2                     []                        --\n",
      "|    |    └─Conv: 3-18                   [-1, 144, 256]            183,024\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-28                        [-1, 144, 256]            --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-29                        [-1, 144, 256]            --\n",
      "├─Bottleneck: 1                          []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-19                   [-1, 144, 256]            --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-20                   [-1, 144, 256]            --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-30                        [-1, 144, 256]            --\n",
      "├─Sequential: 1                          []                        --\n",
      "|    └─Bottleneck: 2-31                  [-1, 144, 256]            --\n",
      "|    |    └─Conv: 3-21                   [-1, 47, 256]             196,366\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-32                        [-1, 47, 256]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-33                        [-1, 47, 256]             --\n",
      "├─Bottleneck: 1                          []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-22                   [-1, 47, 256]             --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-23                   [-1, 47, 256]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-34                        [-1, 47, 256]             --\n",
      "├─Sequential: 1                          []                        --\n",
      "|    └─Bottleneck: 2                     []                        --\n",
      "|    |    └─Conv: 3-24                   [-1, 144, 256]            183,024\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-35                        [-1, 144, 256]            --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-36                        [-1, 144, 256]            --\n",
      "├─Bottleneck: 1                          []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-25                   [-1, 144, 256]            --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-26                   [-1, 144, 256]            --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-37                        [-1, 144, 256]            --\n",
      "├─AdaptiveAvgPool1d: 1-6                 [-1, 144, 1]              --\n",
      "├─Dropout: 1-7                           [-1, 144]                 --\n",
      "├─Linear: 1-8                            [-1, 5]                   725\n",
      "==========================================================================================\n",
      "Total params: 1,156,705\n",
      "Trainable params: 1,156,705\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 389.40\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 4.68\n",
      "Params size (MB): 4.41\n",
      "Estimated Total Size (MB): 9.10\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "class DR_Model(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    c = 48\n",
    "    self.conv0 = Conv(1, c, k=1, s=1)\n",
    "\n",
    "    self.conv1 = Conv(c, 2*c, k=3, s=2, p=1)\n",
    "    self.c2f1 = Bottleneck(2*c, 2*c, shortcut=True, e=0.5,\n",
    "                           k1=39, d1=2, k2=35, d2=5)\n",
    "    \n",
    "    self.conv2 = Conv(2*c, 3*c, k=3, s=2, p=1)\n",
    "    self.c2f2 = nn.Sequential(\n",
    "        Bottleneck(3*c, 3*c, shortcut=True, e=0.333,\n",
    "                           k1=29, d1=2, k2=27, d2=5),\n",
    "        Bottleneck(3*c, 3*c, shortcut=True, e=0.333,\n",
    "                           k1=29, d1=2, k2=27, d2=5)\n",
    "    )\n",
    "    \n",
    "    self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "    self.drop = nn.Dropout(p=0.)\n",
    "    self.fc = nn.Linear(3*c, 5)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    # x.shape: (batch, 1024, 1)\n",
    "    x = self.conv0(x)\n",
    "\n",
    "    x = self.conv1(x)\n",
    "    x = self.c2f1(x)\n",
    "    \n",
    "    x = self.conv2(x)\n",
    "    x = self.c2f2(x)\n",
    "    \n",
    "    x = self.pool(x).flatten(1)\n",
    "    x = self.drop(x)\n",
    "    x = self.fc(x) \n",
    "    return x\n",
    "  \n",
    "if __name__ == \"__main__\":\n",
    "    x = torch.randn(size=(5,1,1024))\n",
    "    test_model = DR_Model()\n",
    "\n",
    "    output = test_model(x)\n",
    "    print(f'输入尺寸为:{x.shape}')\n",
    "    print(f'输出尺寸为:{output.shape}')\n",
    "    from torchsummary import summary\n",
    "    summary(test_model,(1,1024),device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入尺寸为:torch.Size([5, 1, 1024])\n",
      "输出尺寸为:torch.Size([5, 5])\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv: 1-1                              [-1, 48, 1024]            --\n",
      "|    └─Conv1d: 2-1                       [-1, 48, 1024]            48\n",
      "|    └─BatchNorm1d: 2-2                  [-1, 48, 1024]            96\n",
      "|    └─SiLU: 2-3                         [-1, 48, 1024]            --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-4                         [-1, 48, 1024]            --\n",
      "├─C2f: 1                                 []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-1                    [-1, 48, 1024]            --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-2                    [-1, 48, 1024]            --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-5                         [-1, 48, 1024]            --\n",
      "├─C2f: 1                                 []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-3                    [-1, 48, 1024]            --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-4                    [-1, 48, 1024]            --\n",
      "├─Conv: 1-2                              [-1, 96, 512]             --\n",
      "|    └─Conv1d: 2-6                       [-1, 96, 512]             13,824\n",
      "|    └─BatchNorm1d: 2-7                  [-1, 96, 512]             192\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-8                         [-1, 96, 512]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-9                         [-1, 96, 512]             --\n",
      "├─C2f: 1                                 []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-5                    [-1, 96, 512]             --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-6                    [-1, 96, 512]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-10                        [-1, 96, 512]             --\n",
      "├─C2f: 1                                 []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-7                    [-1, 96, 512]             --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-8                    [-1, 96, 512]             --\n",
      "├─C2f: 1-3                               [-1, 96, 512]             --\n",
      "|    └─Conv: 2-11                        [-1, 96, 512]             --\n",
      "|    |    └─Conv1d: 3-9                  [-1, 96, 512]             9,216\n",
      "|    |    └─BatchNorm1d: 3-10            [-1, 96, 512]             192\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-12                        [-1, 96, 512]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-13                        [-1, 96, 512]             --\n",
      "├─C2f: 1                                 []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-11                   [-1, 96, 512]             --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-12                   [-1, 96, 512]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-14                        [-1, 96, 512]             --\n",
      "├─C2f: 1                                 []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-13                   [-1, 96, 512]             --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-14                   [-1, 96, 512]             --\n",
      "├─C2f: 1                                 []                        --\n",
      "|    └─ModuleList: 2                     []                        --\n",
      "|    |    └─Bottleneck: 3-15             [-1, 48, 512]             170,688\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-15                        [-1, 48, 512]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-16                        [-1, 48, 512]             --\n",
      "├─C2f: 1                                 []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-16                   [-1, 48, 512]             --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-17                   [-1, 48, 512]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-17                        [-1, 48, 512]             --\n",
      "├─C2f: 1                                 []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-18                   [-1, 48, 512]             --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-19                   [-1, 48, 512]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-18                        [-1, 48, 512]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-19                        [-1, 48, 512]             --\n",
      "├─C2f: 1                                 []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-20                   [-1, 48, 512]             --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-21                   [-1, 48, 512]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-20                        [-1, 48, 512]             --\n",
      "├─C2f: 1                                 []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-22                   [-1, 48, 512]             --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-23                   [-1, 48, 512]             --\n",
      "├─C2f: 1                                 []                        --\n",
      "|    └─Conv: 2-21                        [-1, 96, 512]             --\n",
      "|    |    └─Conv1d: 3-24                 [-1, 96, 512]             13,824\n",
      "|    |    └─BatchNorm1d: 3-25            [-1, 96, 512]             192\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-22                        [-1, 96, 512]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-23                        [-1, 96, 512]             --\n",
      "├─C2f: 1                                 []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-26                   [-1, 96, 512]             --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-27                   [-1, 96, 512]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-24                        [-1, 96, 512]             --\n",
      "├─C2f: 1                                 []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-28                   [-1, 96, 512]             --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-29                   [-1, 96, 512]             --\n",
      "├─Conv: 1-4                              [-1, 144, 256]            --\n",
      "|    └─Conv1d: 2-25                      [-1, 144, 256]            41,472\n",
      "|    └─BatchNorm1d: 2-26                 [-1, 144, 256]            288\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-27                        [-1, 144, 256]            --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-28                        [-1, 144, 256]            --\n",
      "├─C2f: 1                                 []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-30                   [-1, 144, 256]            --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-31                   [-1, 144, 256]            --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-29                        [-1, 144, 256]            --\n",
      "├─C2f: 1                                 []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-32                   [-1, 144, 256]            --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-33                   [-1, 144, 256]            --\n",
      "├─C2f: 1-5                               [-1, 144, 256]            --\n",
      "|    └─Conv: 2-30                        [-1, 144, 256]            --\n",
      "|    |    └─Conv1d: 3-34                 [-1, 144, 256]            20,736\n",
      "|    |    └─BatchNorm1d: 3-35            [-1, 144, 256]            288\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-31                        [-1, 144, 256]            --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-32                        [-1, 144, 256]            --\n",
      "├─C2f: 1                                 []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-36                   [-1, 144, 256]            --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-37                   [-1, 144, 256]            --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-33                        [-1, 144, 256]            --\n",
      "├─C2f: 1                                 []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-38                   [-1, 144, 256]            --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-39                   [-1, 144, 256]            --\n",
      "|    └─ModuleList: 2                     []                        --\n",
      "|    |    └─Bottleneck: 3-40             [-1, 72, 256]             290,592\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-34                        [-1, 72, 256]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-35                        [-1, 72, 256]             --\n",
      "├─C2f: 1                                 []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-41                   [-1, 72, 256]             --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-42                   [-1, 72, 256]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-36                        [-1, 72, 256]             --\n",
      "├─C2f: 1                                 []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-43                   [-1, 72, 256]             --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-44                   [-1, 72, 256]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-37                        [-1, 72, 256]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-38                        [-1, 72, 256]             --\n",
      "├─C2f: 1                                 []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-45                   [-1, 72, 256]             --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-46                   [-1, 72, 256]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-39                        [-1, 72, 256]             --\n",
      "├─C2f: 1                                 []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-47                   [-1, 72, 256]             --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-48                   [-1, 72, 256]             --\n",
      "|    └─ModuleList: 2                     []                        --\n",
      "|    |    └─Bottleneck: 3-49             [-1, 72, 256]             290,592\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-40                        [-1, 72, 256]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-41                        [-1, 72, 256]             --\n",
      "├─C2f: 1                                 []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-50                   [-1, 72, 256]             --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-51                   [-1, 72, 256]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-42                        [-1, 72, 256]             --\n",
      "├─C2f: 1                                 []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-52                   [-1, 72, 256]             --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-53                   [-1, 72, 256]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-43                        [-1, 72, 256]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-44                        [-1, 72, 256]             --\n",
      "├─C2f: 1                                 []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-54                   [-1, 72, 256]             --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-55                   [-1, 72, 256]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-45                        [-1, 72, 256]             --\n",
      "├─C2f: 1                                 []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-56                   [-1, 72, 256]             --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-57                   [-1, 72, 256]             --\n",
      "|    └─Conv: 2-46                        [-1, 144, 256]            --\n",
      "|    |    └─Conv1d: 3-58                 [-1, 144, 256]            41,472\n",
      "|    |    └─BatchNorm1d: 3-59            [-1, 144, 256]            288\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-47                        [-1, 144, 256]            --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-48                        [-1, 144, 256]            --\n",
      "├─C2f: 1                                 []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-60                   [-1, 144, 256]            --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-61                   [-1, 144, 256]            --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-49                        [-1, 144, 256]            --\n",
      "├─C2f: 1                                 []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-62                   [-1, 144, 256]            --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-63                   [-1, 144, 256]            --\n",
      "├─AdaptiveAvgPool1d: 1-6                 [-1, 144, 1]              --\n",
      "├─Dropout: 1-7                           [-1, 144]                 --\n",
      "├─Linear: 1-8                            [-1, 5]                   725\n",
      "==========================================================================================\n",
      "Total params: 894,725\n",
      "Trainable params: 894,725\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 47.95\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 4.69\n",
      "Params size (MB): 3.41\n",
      "Estimated Total Size (MB): 8.10\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "class DR_C2fNet(torch.nn.Module):  # You Only Read Once\n",
    "    def __init__(self, in_channels=1, classes=5):\n",
    "        super().__init__()\n",
    "        c = 48\n",
    "        self.conv0 = Conv(1, c, k=1, s=1)\n",
    "\n",
    "        self.conv1 = Conv(c, 2*c, k=3, s=2, p=1)\n",
    "        self.c2f1 = C2f(2*c, 2*c, n=1, shortcut=True, e=0.5,\n",
    "                                k1=39, d1=2, k2=35, d2=5)\n",
    "        \n",
    "        self.conv2 = Conv(2*c, 3*c, k=3, s=2, p=1)\n",
    "        self.c2f2 = C2f(3*c, 3*c, n=2, shortcut=True, e=0.5,\n",
    "                                k1=29, d1=2, k2=27, d2=5)\n",
    "        \n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.drop = nn.Dropout(p=0.)\n",
    "        self.fc = nn.Linear(3*c, 5)\n",
    "  \n",
    "    def forward(self, x):\n",
    "        # x.shape: (batch, 1024, 1)\n",
    "        x = self.conv0(x)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.c2f1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.c2f2(x)\n",
    "        \n",
    "        x = self.pool(x).flatten(1)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc(x) \n",
    "        return x \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    x = torch.randn(size=(5,1,1024))\n",
    "    test_model = DR_C2fNet()\n",
    "\n",
    "    output = test_model(x)\n",
    "    print(f'输入尺寸为:{x.shape}')\n",
    "    print(f'输出尺寸为:{output.shape}')\n",
    "    from torchsummary import summary\n",
    "    summary(test_model,(1,1024),device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入尺寸为:torch.Size([5, 1, 1024])\n",
      "输出尺寸为:torch.Size([5, 5])\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv: 1-1                              [-1, 48, 1024]            --\n",
      "|    └─Conv1d: 2-1                       [-1, 48, 1024]            48\n",
      "|    └─BatchNorm1d: 2-2                  [-1, 48, 1024]            96\n",
      "|    └─SiLU: 2-3                         [-1, 48, 1024]            --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-4                         [-1, 48, 1024]            --\n",
      "├─dilated_c2f1: 1                        []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-1                    [-1, 48, 1024]            --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-5                         [-1, 48, 1024]            --\n",
      "├─dilated_c2f2: 1                        []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-2                    [-1, 48, 1024]            --\n",
      "├─Conv: 1-2                              [-1, 96, 512]             --\n",
      "|    └─Conv1d: 2-6                       [-1, 96, 512]             13,824\n",
      "|    └─BatchNorm1d: 2-7                  [-1, 96, 512]             192\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-8                         [-1, 96, 512]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-9                         [-1, 96, 512]             --\n",
      "├─dilated_c2f1: 1                        []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-3                    [-1, 96, 512]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-10                        [-1, 96, 512]             --\n",
      "├─dilated_c2f2: 1                        []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-4                    [-1, 96, 512]             --\n",
      "├─dilated_c2f1: 1-3                      [-1, 96, 512]             --\n",
      "|    └─ARNet: 2-11                       [-1, 96, 512]             --\n",
      "|    |    └─AdaptiveAvgPool1d: 3-5       [-1, 96, 1]               --\n",
      "|    |    └─Sequential: 3-6              [-1, 96]                  18,432\n",
      "|    └─ModuleList: 2                     []                        --\n",
      "|    |    └─Bottleneck: 3-7              [-1, 48, 512]             170,688\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-12                        [-1, 48, 512]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-13                        [-1, 48, 512]             --\n",
      "├─dilated_c2f1: 1                        []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-8                    [-1, 48, 512]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-14                        [-1, 48, 512]             --\n",
      "├─dilated_c2f2: 1                        []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-9                    [-1, 48, 512]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-15                        [-1, 48, 512]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-16                        [-1, 48, 512]             --\n",
      "├─dilated_c2f1: 1                        []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-10                   [-1, 48, 512]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-17                        [-1, 48, 512]             --\n",
      "├─dilated_c2f2: 1                        []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-11                   [-1, 48, 512]             --\n",
      "├─dilated_c2f1: 1                        []                        --\n",
      "|    └─Conv: 2-18                        [-1, 96, 512]             --\n",
      "|    |    └─Conv1d: 3-12                 [-1, 96, 512]             13,824\n",
      "|    |    └─BatchNorm1d: 3-13            [-1, 96, 512]             192\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-19                        [-1, 96, 512]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-20                        [-1, 96, 512]             --\n",
      "├─dilated_c2f1: 1                        []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-14                   [-1, 96, 512]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-21                        [-1, 96, 512]             --\n",
      "├─dilated_c2f2: 1                        []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-15                   [-1, 96, 512]             --\n",
      "├─Conv: 1-4                              [-1, 144, 256]            --\n",
      "|    └─Conv1d: 2-22                      [-1, 144, 256]            41,472\n",
      "|    └─BatchNorm1d: 2-23                 [-1, 144, 256]            288\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-24                        [-1, 144, 256]            --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-25                        [-1, 144, 256]            --\n",
      "├─dilated_c2f1: 1                        []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-16                   [-1, 144, 256]            --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-26                        [-1, 144, 256]            --\n",
      "├─dilated_c2f2: 1                        []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-17                   [-1, 144, 256]            --\n",
      "├─dilated_c2f2: 1-5                      [-1, 144, 256]            --\n",
      "|    └─ARNet: 2-27                       [-1, 144, 256]            --\n",
      "|    |    └─AdaptiveAvgPool1d: 3-18      [-1, 144, 1]              --\n",
      "|    |    └─Sequential: 3-19             [-1, 144]                 41,472\n",
      "|    └─ModuleList: 2                     []                        --\n",
      "|    |    └─Bottleneck: 3-20             [-1, 96, 256]             516,480\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-28                        [-1, 96, 256]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-29                        [-1, 96, 256]             --\n",
      "├─dilated_c2f1: 1                        []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-21                   [-1, 96, 256]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-30                        [-1, 96, 256]             --\n",
      "├─dilated_c2f2: 1                        []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-22                   [-1, 96, 256]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-31                        [-1, 96, 256]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-32                        [-1, 96, 256]             --\n",
      "├─dilated_c2f1: 1                        []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-23                   [-1, 96, 256]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-33                        [-1, 96, 256]             --\n",
      "├─dilated_c2f2: 1                        []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-24                   [-1, 96, 256]             --\n",
      "|    └─ARNet: 2-34                       [-1, 96, 256]             --\n",
      "|    |    └─AdaptiveAvgPool1d: 3-25      [-1, 96, 1]               --\n",
      "|    |    └─Sequential: 3-26             [-1, 96]                  18,432\n",
      "|    └─ModuleList: 2                     []                        --\n",
      "|    |    └─Bottleneck: 3-27             [-1, 48, 256]             129,216\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-35                        [-1, 48, 256]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-36                        [-1, 48, 256]             --\n",
      "├─dilated_c2f1: 1                        []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-28                   [-1, 48, 256]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-37                        [-1, 48, 256]             --\n",
      "├─dilated_c2f2: 1                        []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-29                   [-1, 48, 256]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-38                        [-1, 48, 256]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-39                        [-1, 48, 256]             --\n",
      "├─dilated_c2f1: 1                        []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-30                   [-1, 48, 256]             --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-40                        [-1, 48, 256]             --\n",
      "├─dilated_c2f2: 1                        []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-31                   [-1, 48, 256]             --\n",
      "|    └─Conv: 2-41                        [-1, 144, 256]            --\n",
      "|    |    └─Conv1d: 3-32                 [-1, 144, 256]            41,472\n",
      "|    |    └─BatchNorm1d: 3-33            [-1, 144, 256]            288\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-42                        [-1, 144, 256]            --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-43                        [-1, 144, 256]            --\n",
      "├─dilated_c2f1: 1                        []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-34                   [-1, 144, 256]            --\n",
      "├─Conv: 1                                []                        --\n",
      "|    └─SiLU: 2-44                        [-1, 144, 256]            --\n",
      "├─dilated_c2f2: 1                        []                        --\n",
      "|    └─Conv: 2                           []                        --\n",
      "|    |    └─SiLU: 3-35                   [-1, 144, 256]            --\n",
      "├─AdaptiveAvgPool1d: 1-6                 [-1, 144, 1]              --\n",
      "├─Dropout: 1-7                           [-1, 144]                 --\n",
      "├─Linear: 1-8                            [-1, 5]                   725\n",
      "==========================================================================================\n",
      "Total params: 1,007,141\n",
      "Trainable params: 1,007,141\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 38.37\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 3.38\n",
      "Params size (MB): 3.84\n",
      "Estimated Total Size (MB): 7.23\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "class DR_CSPNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    c = 48\n",
    "    self.conv0 = Conv(1, c, k=1, s=1)\n",
    "\n",
    "    self.conv1 = Conv(c, 2*c, k=3, s=2, p=1)\n",
    "    self.c2f1 = dilated_c2f1(2*c, 2*c, n=1, shortcut=True, e=1,\n",
    "                             k1=39, d1=2, k2=35, d2=5)\n",
    "    \n",
    "    self.conv2 = Conv(2*c, 3*c, k=3, s=2, p=1)\n",
    "    self.c2f2 = dilated_c2f2(3*c, 3*c, n=1, shortcut=True, e=1,\n",
    "                             k1=29, d1=2, k2=27, d2=5)\n",
    "    \n",
    "    self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "    self.drop = nn.Dropout(p=0.)\n",
    "    self.fc = nn.Linear(3*c, 5)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    # x.shape: (batch, 1024, 1)\n",
    "    x = self.conv0(x)\n",
    "\n",
    "    x = self.conv1(x)\n",
    "    x = self.c2f1(x)\n",
    "    \n",
    "    x = self.conv2(x)\n",
    "    x = self.c2f2(x)\n",
    "    \n",
    "    x = self.pool(x).flatten(1)\n",
    "    x = self.drop(x)\n",
    "    x = self.fc(x) \n",
    "    return x\n",
    "  \n",
    "if __name__ == \"__main__\":\n",
    "    x = torch.randn(size=(5,1,1024))\n",
    "    test_model = DR_CSPNet()\n",
    "\n",
    "    output = test_model(x)\n",
    "    print(f'输入尺寸为:{x.shape}')\n",
    "    print(f'输出尺寸为:{output.shape}')\n",
    "    from torchsummary import summary\n",
    "    summary(test_model,(1,1024),device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:57<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "折1, train_time(second): 37.96668028831482\n",
      "折1, 训练log accuracy0.857500, 验证log accuracy0.836250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:56<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "折2, train_time(second): 37.201449394226074\n",
      "折2, 训练log accuracy0.992188, 验证log accuracy0.803750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:53<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "折3, train_time(second): 35.26267647743225\n",
      "折3, 训练log accuracy0.857187, 验证log accuracy0.831250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:51<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "折4, train_time(second): 34.46069049835205\n",
      "折4, 训练log accuracy0.948125, 验证log accuracy0.825000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:49<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "折5, train_time(second): 33.245869636535645\n",
      "折5, 训练log accuracy0.913750, 验证log accuracy0.847500\n",
      "train_a 0.9137500000000001\n",
      "valid_a 0.8287500000000001\n",
      "valid_s 0.01451292527370002\n",
      "time 35.62747325897217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_net(device):\n",
    "    net = Model().to(device=device)\n",
    "    return net\n",
    "\n",
    "train_a, valid_a, valid_s, average_time = k_fold(data_x, data_y, 'Model', device,\n",
    "                        k=5, num_epochs=70, learning_rate=0.001)\n",
    "print('train_a', train_a)\n",
    "print('valid_a', valid_a)\n",
    "print('valid_s', valid_s)\n",
    "print('time', average_time)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [01:23<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "折1, train_time(second): 53.67281699180603\n",
      "折1, 训练log accuracy0.997812, 验证log accuracy0.825000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [02:50<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "折2, train_time(second): 102.5855495929718\n",
      "折2, 训练log accuracy0.986250, 验证log accuracy0.797500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [02:56<00:00,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "折3, train_time(second): 105.66736578941345\n",
      "折3, 训练log accuracy0.998750, 验证log accuracy0.803750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [02:46<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "折4, train_time(second): 101.17875742912292\n",
      "折4, 训练log accuracy0.972500, 验证log accuracy0.811250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [02:46<00:00,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "折5, train_time(second): 100.85824346542358\n",
      "折5, 训练log accuracy0.995625, 验证log accuracy0.822500\n",
      "train_a 0.9901875\n",
      "valid_a 0.8119999999999999\n",
      "valid_s 0.01056527330455772\n",
      "time 92.79254665374756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_net(device):\n",
    "    net = C2fNet().to(device=device)\n",
    "    return net\n",
    "\n",
    "train_a, valid_a, valid_s, average_time = k_fold(data_x, data_y, 'Model', device,\n",
    "                        k=5, num_epochs=70, learning_rate=0.001)\n",
    "print('train_a', train_a)\n",
    "print('valid_a', valid_a)\n",
    "print('valid_s', valid_s)\n",
    "print('time', average_time)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [02:58<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "折1, train_time(second): 106.53149771690369\n",
      "折1, 训练log accuracy0.820000, 验证log accuracy0.842500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [02:55<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "折2, train_time(second): 105.23914313316345\n",
      "折2, 训练log accuracy0.847812, 验证log accuracy0.798750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [02:41<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "折3, train_time(second): 96.3538179397583\n",
      "折3, 训练log accuracy0.833125, 验证log accuracy0.828750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [02:56<00:00,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "折4, train_time(second): 104.96138525009155\n",
      "折4, 训练log accuracy0.847500, 验证log accuracy0.838750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [03:03<00:00,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "折5, train_time(second): 110.83559465408325\n",
      "折5, 训练log accuracy0.835000, 验证log accuracy0.836250\n",
      "train_a 0.8366875\n",
      "valid_a 0.829\n",
      "valid_s 0.015779733838059525\n",
      "time 104.78428773880005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_net(device):\n",
    "    net = CSPNet().to(device=device)\n",
    "    return net\n",
    "\n",
    "train_a, valid_a, valid_s, average_time = k_fold(data_x, data_y, 'Model', device,\n",
    "                        k=5, num_epochs=70, learning_rate=0.001)\n",
    "print('train_a', train_a)\n",
    "print('valid_a', valid_a)\n",
    "print('valid_s', valid_s)\n",
    "print('time', average_time)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [14:13<00:00, 12.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "折1, train_time(second): 567.4440958499908\n",
      "折1, 训练log accuracy1.000000, 验证log accuracy0.923750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [11:54<00:00, 10.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "折2, train_time(second): 470.6830806732178\n",
      "折2, 训练log accuracy1.000000, 验证log accuracy0.910000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [11:32<00:00,  9.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "折3, train_time(second): 450.6396200656891\n",
      "折3, 训练log accuracy1.000000, 验证log accuracy0.910000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [11:51<00:00, 10.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "折4, train_time(second): 472.4804162979126\n",
      "折4, 训练log accuracy1.000000, 验证log accuracy0.908750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [11:43<00:00, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "折5, train_time(second): 461.54386496543884\n",
      "折5, 训练log accuracy1.000000, 验证log accuracy0.926250\n",
      "train_a 1.0\n",
      "valid_a 0.9157499999999998\n",
      "valid_s 0.007607562027351467\n",
      "time 484.5582155704498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_net(device):\n",
    "    net = DR_Model().to(device=device)\n",
    "    return net\n",
    "\n",
    "train_a, valid_a, valid_s, average_time = k_fold(data_x, data_y, 'Model', device,\n",
    "                        k=5, num_epochs=70, learning_rate=0.001)\n",
    "print('train_a', train_a)\n",
    "print('valid_a', valid_a)\n",
    "print('valid_s', valid_s)\n",
    "print('time', average_time)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [07:24<00:00,  6.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "折1, train_time(second): 285.4180600643158\n",
      "折1, 训练log accuracy1.000000, 验证log accuracy0.923750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [01:46<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "折2, train_time(second): 71.3738181591034\n",
      "折2, 训练log accuracy1.000000, 验证log accuracy0.922500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [01:46<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "折3, train_time(second): 71.35899329185486\n",
      "折3, 训练log accuracy0.993750, 验证log accuracy0.905000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [01:46<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "折4, train_time(second): 71.36263656616211\n",
      "折4, 训练log accuracy1.000000, 验证log accuracy0.930000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [01:46<00:00,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "折5, train_time(second): 71.29330086708069\n",
      "折5, 训练log accuracy1.000000, 验证log accuracy0.921250\n",
      "train_a 0.99875\n",
      "valid_a 0.9205\n",
      "valid_s 0.008314144574157942\n",
      "time 114.16136178970336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_net(device):\n",
    "    net = DR_C2fNet().to(device=device)\n",
    "    return net\n",
    "\n",
    "train_a, valid_a, valid_s, average_time = k_fold(data_x, data_y, 'Model', device,\n",
    "                        k=5, num_epochs=70, learning_rate=0.001)\n",
    "print('train_a', train_a)\n",
    "print('valid_a', valid_a)\n",
    "print('valid_s', valid_s)\n",
    "print('time', average_time)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [01:32<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "折1, train_time(second): 64.27543139457703\n",
      "折1, 训练log accuracy1.000000, 验证log accuracy0.937500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [01:32<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "折2, train_time(second): 64.21233129501343\n",
      "折2, 训练log accuracy0.996563, 验证log accuracy0.936250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [01:32<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "折3, train_time(second): 64.21764159202576\n",
      "折3, 训练log accuracy0.997188, 验证log accuracy0.933750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [01:32<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "折4, train_time(second): 64.27298903465271\n",
      "折4, 训练log accuracy0.999687, 验证log accuracy0.928750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [01:32<00:00,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "折5, train_time(second): 64.29162383079529\n",
      "折5, 训练log accuracy0.986563, 验证log accuracy0.927500\n",
      "train_a 0.9959999999999999\n",
      "valid_a 0.9327500000000001\n",
      "valid_s 0.00398434436262732\n",
      "time 64.25400342941285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_net(device):\n",
    "    net = DR_CSPNet().to(device=device)\n",
    "    return net\n",
    "\n",
    "train_a, valid_a, valid_s, average_time = k_fold(data_x, data_y, 'Model', device,\n",
    "                        k=5, num_epochs=70, learning_rate=0.001)\n",
    "print('train_a', train_a)\n",
    "print('valid_a', valid_a)\n",
    "print('valid_s', valid_s)\n",
    "print('time', average_time)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
